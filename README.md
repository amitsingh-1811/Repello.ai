# AI Research Agent

An intelligent full-stack application that autonomously researches web information to answer complex user queries. The system performs web searches, scrapes relevant content, and uses AI to synthesize comprehensive answers with source citations.

## ğŸš€ Features

- **Interactive Web Interface**: Clean React.js frontend with search functionality
- **Autonomous Web Research**: Automated Google search and content extraction
- **Multi-source Analysis**: Scrapes and analyzes top search results
- **AI-Powered Synthesis**: Uses Llama 3.2:1b model for intelligent answer generation
- **Source Citations**: Provides credible references with URLs and titles
- **Error Handling**: Robust error management for network and processing issues

## ğŸ—ï¸ Architecture

### Frontend (React.js)
- **Components**: Modular React components for UI elements
- User-friendly search interface
- Real-time query processing
- Error handling and user feedback
- Response display with source links

### Backend (Python)
The backend is structured with a clean separation of concerns:

#### API Layer (`app/api/`)
- **main.py**: Main application entry point and API endpoints
- Handles HTTP requests and responses
- Coordinates between services

#### Service Layer (`app/services/`)
- **search.py**: SerpAPI integration for web search functionality
- **llm_client.py**: Llama 3.2:1b model interface and LlamaIndex operations
- Business logic and core processing

#### Scrapy Project (`myProject/`)
- **spiders/example_spider.py**: Web scraping spider implementation
- **middlewares.py**: Custom downloader middlewares
- **settings.py**: Scrapy configuration and settings

The backend processing follows three main milestones:

#### Milestone 1: Web Search
- **Technology**: SerpAPI integration
- **Function**: Performs Google searches and retrieves top result URLs
- **Output**: Ranked list of relevant web pages

#### Milestone 2: Content Extraction
- **Technology**: Scrapy + Splash
- **Function**: Scrapes content from top 3 search results
- **Processing**: Runs on separate threads for optimal performance
- **Output**: Clean, structured text data from web sources

#### Milestone 3: AI Analysis & Synthesis
- **Technology**: Llama 3.2:1b + LlamaIndex
- **Function**: 
  - Chunks scraped content using LlamaIndex
  - Creates vector index of resources
  - Queries the index with user's question
  - Synthesizes comprehensive answer
- **Output**: Structured response with source citations

## ğŸ› ï¸ Technology Stack

### Frontend
- **React.js** - User interface framework
- **JavaScript/JSX** - Frontend logic and components

### Backend
- **Python** - Core backend language
- **SerpAPI** - Google search integration
- **Scrapy** - Web scraping framework
- **Splash** - JavaScript rendering service
- **Llama 3.2:1b** - Large language model
- **LlamaIndex** - Document indexing and retrieval
- **Multiprocessing** - Used to run Scrapy in isolated processes to avoid Twisted reactor conflicts



## ğŸ“‹ Prerequisites

- Node.js
- Python
- SerpAPI key
- Splash server running
- Ollama or compatible LLM runtime

## ğŸ’¡ Usage

1. **Start the Application**
   - Launch the backend server
   - Start the React frontend
   - Ensure Splash server is running

2. **Query the System**
   - Enter your question in the search bar
   - Click the send button
   - Wait for the AI to research and respond

3. **View Results**
   - Read the synthesized answer
   - Check provided source links
   - Review any error messages if issues occur

## ğŸ”„ Processing Flow

```
User Query â†’ Frontend â†’ Backend API
    â†“
SerpAPI Search â†’ Top URLs Retrieved
    â†“
Scrapy + Splash â†’ Content Extraction (Threaded)
    â†“
LlamaIndex Chunking â†’ Vector Index Creation
    â†“
Llama 3.2:1b Processing â†’ Answer Synthesis
    â†“
Response with Citations â†’ Frontend Display
```

## ğŸ›¡ï¸ Error Handling

- **Network Errors**: Graceful handling of connection issues
- **Scraping Failures**: Fallback mechanisms for inaccessible content
- **LLM Processing**: Timeout and error recovery for model inference
- **User Feedback**: Clear error messages displayed in frontend

## ğŸ¯ Example Use Cases

- **Product Comparisons**: *"Compare the latest electric vehicle models and their safety features"*
- **Market Research**: *"What are the current trends in renewable energy investment?"*
- **Technical Analysis**: *"Explain the latest developments in quantum computing"*
- **News Synthesis**: *"Summarize recent developments in AI regulation"*

## ğŸ“ Project Structure

```
ai-research-agent/
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ package-lock.json
â”‚
â””â”€â”€ backend/
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ api/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â””â”€â”€ main.py
    â”‚   â”œâ”€â”€ services/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ llm_client.py
    â”‚   â”‚   â””â”€â”€ search.py
    â”‚   â””â”€â”€ __init__.py
    â”œâ”€â”€ myProject/
    â”‚   â”œâ”€â”€ spiders/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â””â”€â”€ example_spider.py
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ items.py
    â”‚   â”œâ”€â”€ middlewares.py
    â”‚   â”œâ”€â”€ pipelines.py
    â”‚   â””â”€â”€ settings.py
    â”œâ”€â”€ .gitignore
    â””â”€â”€ scrapy.cfg
```
